{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ozvnExGZpfh"
      },
      "source": [
        "# Density simulation of a path-dependent McKean-Vlasov SDE with linear interaction\n",
        "\n",
        "\n",
        "> This notebook implements the simulations described in Section 2.1.1 of\n",
        "  - [1] Bernou, A. and Liu, Y. (2024). Particle method for the numerical simulation of the path-dependent McKean-Vlasov equation\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "**Contents**\n",
        "\n",
        "* [1. Definition of the McKean-Vlasov equation, the particle system and the Euler scheme](#chapter1)\n",
        "\n",
        "* [2. Application: Simulation with fixed M](#chapter2)\n",
        "\n",
        "* [3. Application: Simulation with M depending on N](#chapter3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "-------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-QB8CBdZpfl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from joblib import Parallel, delayed\n",
        "import time\n",
        "import shutil\n",
        "from functools import partialmethod\n",
        "from scipy import special\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from scipy.stats import wasserstein_distance\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FW2Qj0ZZpfm"
      },
      "source": [
        "## I. Definition of the McKean-Vlasov equation, the particle system and the Euler scheme <a class=\"anchor\" id=\"chapter1\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1CLVQUyZpfm"
      },
      "source": [
        "We consider a stochastic process $(X_t)_{t\\in[0, T]}$ defined by the following McKean-Vlasov SDE with linear interaction\n",
        "\n",
        "$$dX_t = - 2 \\int_0^t  \\int_{\\mathbb{R}}(X_t-x)\\mu_s(dx) \\, ds \\, dt+dB_t\\quad \\text{with}\\quad X_0\\sim \\mathcal{N}(0,1),\\hspace{2cm}(1)$$\n",
        "\n",
        "where for every  $t\\in[0,T]$, $\\mu_t$ denotes the probability distribution of $X_t$.  This process $(X_t)_{t\\in[0, T]}$ is a time-dependent Ornstein-Uhlenbeck process, namely, for every $t\\in[0,T], \\; \\mu_t=\\mathcal{N}\\big(0, e^{-2t^2}(1 + \\int_0^t e^{2 r^2} \\, dr) \\big)$ (see [1, Proposition 2.1])."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oh_-xa2Zpfm"
      },
      "source": [
        "Let $N$ be the number of particles. The $N$-particle system $(X_t^{1}, ..., X_t^{N})_{t\\in[0,T]}$ corresponding to (1) is defined as follows :\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "dX_t^{n}=- 2 \\int_0^t \\frac{1}{N} \\sum_{i=1}^{N}\\big(X_t^{n}-X_s^{i}\\big) ds \\, dt+ B_t^{n}.\\hspace{2cm}(2),\n",
        "\\end{equation}\n",
        "where, for all $n \\in \\{1,\\dots,N\\}$, $(B^n_t)_{t \\ge 0}$ is a standard Brownian motion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUeVgs7RZpfn"
      },
      "source": [
        "Let $M$ denote the time discretization number for the Euler scheme. Set $h=\\frac{T}{M}$ and $t_m=m\\cdot h, 0\\leq m\\leq M$. Combining the particle system (2) and the Euler scheme, we obtain the following discrete particle system (see also [1, Definition 1.4] and [1, equation (1.11)]: for $1 \\le n \\le N$,\n",
        "\n",
        "\\begin{equation}\n",
        "X^n_{t_1} = X^n_0 +  \\sqrt{h} Z^n_1\n",
        "\\end{equation}\n",
        "and for $1 \\le m \\le M-1$,\n",
        "\\begin{align}\n",
        "X^n_{t_{m+1}} &= X^n_{t_m} + \\frac{h^2}{N} \\sum_{j=1}^N \\Big( \\frac{X^j_{t_0}}{2} + \\frac{X^j_{t_m}}{2} + \\sum_{k=1}^{m-1} X^j_{t_k} \\Big) - h \\, t_m \\, X^n_{t_m} + \\sqrt{h} Z^n_{m+1},\n",
        "\\end{align}\n",
        "where $ \\: Z_{m+1}^{n}:=\\frac{1}{\\sqrt{h}}(B^n_{t_{m+1}}-B^n_{t_{m}})$ are i.i.d random variables having the standard normal distribution $\\mathcal{N}(0,1)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTJ0dTcoZpfo"
      },
      "source": [
        "In the next cell, the function `Euler_one_step` defines the operator of the Euler scheme for one time step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiNdIVvNZpfq"
      },
      "outputs": [],
      "source": [
        "def Euler_first_step(X_in, N_in, h):\n",
        "    nn=np.ones(N_in)/N_in\n",
        "    t_1 = h\n",
        "    EXin=np.matmul(nn, X_in[:,0])\n",
        "    X_in[:, 1] = X_in[:,0] + np.sqrt(h)*np.random.normal(0, 1, N_in)\n",
        "    return X_in[:,1]\n",
        "\n",
        "def Euler_one_step(step_in,X_in,N_in, h):\n",
        "    nn=np.ones(N_in)/N_in\n",
        "    t_in = step_in*h\n",
        "    EXin=np.matmul(np.transpose(X_in), nn)\n",
        "    X_out=(1-2*h*t_in)*X_in[:, step_in]+ (h**2)*(EXin[0] + EXin[step_in]) + 2*(h**2)*(np.sum(EXin[1:step_in-1])) +np.sqrt(h)*np.random.normal(0, 1, N_in)\n",
        "    return X_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Brd5gFGda8-"
      },
      "source": [
        "# II/ Application: Simulation with fixed $M$. <a class=\"anchor\" id=\"chapter2\"></a>\n",
        "The code of this section is the one used to generate [1, Figure 1].\n",
        "\n",
        "By default, this section is set with parameter $M=200$.\n",
        "\n",
        "Modifying the parameters with $M = 10$, $pn = 12$ and $base = 7$ below, this code can also generate [1, Figure 3].\n",
        "\n",
        "## 1) Simulation of the particle system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2KDQICwdzxh"
      },
      "outputs": [],
      "source": [
        "## Parameters\n",
        "T=1.\n",
        "M=200  # Time discretization number, adapted in the next sections.\n",
        "h=T/M  # Time step\n",
        "m_X0=0\n",
        "pn = 12\n",
        "base = 7\n",
        "N_power=np.linspace(base,base+pn-1,pn)\n",
        "N_vec=2**N_power.astype(int)\n",
        "print(\"M=\", M)\n",
        "print(\"Vector of the number of particles\", N_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17b_dwA1Zpfs"
      },
      "source": [
        "First, we compute and save the particle systems at time T=1 with different particle numbers in `N_vec`. For each given particle number, we implement 30 identical and independent simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lejB8-ScTLYl"
      },
      "outputs": [],
      "source": [
        "def one_sim(particle_num, repeat, M, h):\n",
        "  particle_process=np.zeros((particle_num,M+1))\n",
        "  particle_process[:,0]=np.random.normal(m_X0, 1, particle_num)\n",
        "  particle_process[:,1]=Euler_first_step(particle_process,particle_num, h)\n",
        "\n",
        "  for m in range(1,M):\n",
        "    particle_process[:,m+1]=Euler_one_step(m, particle_process,particle_num,h)\n",
        "  path = \"particle_num_\"+str(particle_num)+\"repeat\"+str(repeat)+\"step\"+str(M)+\".csv\"\n",
        "  np.savetxt(path, particle_process[:,M], delimiter=\",\")\n",
        "  ## COMPLETE IN THE SECOND LINE INFORMATION ABOUT THE PATH TO SAVE THE DATA\n",
        "  source_path = path\n",
        "  destination_path = '/content/drive/MyDrive/Results_OU_M200/'+path ## UNCOMMENT the previous code to save data\n",
        "  shutil.move(source_path, destination_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkX72hN9T6pZ"
      },
      "outputs": [],
      "source": [
        "# Parallel simulation to run the Monte-Carlo iterations.\n",
        "\n",
        "## Please check the destination_path in the cell above before running this cell\n",
        "NNs = 30\n",
        "\n",
        "start = time.time()\n",
        "for i in range(pn):\n",
        "      print(\"Step\"+str(i)+\", M = \"+str(M)+\", N = \"+str(N_vec[i]))\n",
        "      Parallel(n_jobs = 4)(delayed(one_sim)(N_vec[i], j, M, h) for j in tqdm(range(NNs)))\n",
        "end = time.time()\n",
        "print(end-start)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pn9_w5kZpft"
      },
      "source": [
        "The following cell defines the true density function of $X_T$, which is the law $\\mathcal{N}(0, e^{-2} (1 + \\int_0^1 e^{2r^2} \\, dr))$, see [1, Proposition 2.1]. We note that this last variance is $e^{-2} (1 + \\tfrac 12 \\sqrt{\\frac{\\pi}{2}} \\hbox{erfi}(\\sqrt{2}))$ which is approximately equal to $0.45532932051932784$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWP9jXkAZpfu"
      },
      "outputs": [],
      "source": [
        "# Definition of the true density function\n",
        "\n",
        "pi = 3.14159265359\n",
        "var_approx = np.exp(-2)*(1 + 0.5 * np.sqrt(pi/2)*special.erfi(np.sqrt(2)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKcFHYRjOCSC"
      },
      "source": [
        "## 2) Estimation of the Wasserstein distance\n",
        "\n",
        "In the next cells, we compute an empirical Wasserstein distance, using\n",
        "$$ \\mathcal{W}_2(\\mu,\\nu)^2 = \\int_0^1 \\Big|F_\\mu^{-1}(q) - F_\\nu^{-1}(q) \\Big|^2 \\, d q. $$\n",
        "We start by computing the vector of theoretical quantiles for the target distribution in the next cell. Since we cannot compute the full integral with quantiles over $[0,1]$  as this gives infinite values, we use a truncation parameter epsilon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdZ2voS5d219"
      },
      "outputs": [],
      "source": [
        "def estim_Wp(a,b, epsilon,p): ## takes two vectors of values and compute the estimated integral.\n",
        "    n = len(a) # Since epsilon=precision_integral below, 1/n = epsilon.\n",
        "    res = ((1-2*epsilon)/n)*(((a[0] - b[0])**p + (a[-1]-b[-1])**p)/2 + np.sum((a[1:-1] - b[1:-1])**p))\n",
        "    return(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rlg8hZRPsEU",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "epsilon = 10**(-6) ##\n",
        "p = 2\n",
        "NNs = 30\n",
        "precision_integral = 10**6 ## This parameter is used for the integral discretization\n",
        "quantile_vector = np.arange(0.01,1,1/precision_integral)\n",
        "quantile_theoretical = norm.ppf(quantile_vector, 0, np.sqrt(var_approx))\n",
        "error_basic = np.zeros((pn, NNs))\n",
        "max_error = np.zeros((pn, NNs))\n",
        "error_final = np.zeros(pn)\n",
        "for i in tqdm(range(pn)):   ## particle number\n",
        "    for nns in range(NNs):  ## Monte-Carlo repetition\n",
        "        ## CHANGE THE SECOND LINE below to access data stored somewhere else.\n",
        "        path = \"particle_num_\"+str(N_vec[i])+\"repeat\"+str(nns)+\"step\"+str(M)+\".csv\"\n",
        "        density_particle= np.array(pd.read_csv(\"/content/drive/MyDrive/Results_OU_M200/\"+path, sep=',',header=None))\n",
        "\n",
        "        ## Estimation of the Wasserstein distance with respect to the true distribution.\n",
        "        quantile_method = np.quantile(density_particle, quantile_vector)\n",
        "        error_basic[i, nns] = estim_Wp(quantile_method, quantile_theoretical, epsilon, p)\n",
        "\n",
        "    ### Computing the finate global error\n",
        "    error_final[i] = np.mean(error_basic[i,:]**p)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"error_final_M200.csv\"\n",
        "np.savetxt(path, error_final, delimiter=\",\")"
      ],
      "metadata": {
        "id": "Fe3riFD1OwRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "plt.figure(figsize=(9,7))\n",
        "N_vec_bis = N_vec\n",
        "\n",
        "# Main plot with larger markers and thicker line\n",
        "plt.scatter(np.log2(N_vec_bis), np.log2(error_final),\n",
        "           color=\"blue\", marker=\"o\", s=80, zorder=5,  edgecolors='blue', linewidth=1)\n",
        "plt.plot(np.log2(N_vec_bis), np.log2(error_final),\n",
        "         \"b-\", linewidth=2.5, alpha=0.7)\n",
        "\n",
        "# Optional: Add theoretical slope reference line\n",
        "# If you expect a specific convergence rate, e.g., -1/2:\n",
        "x_theory = np.log2(N_vec_bis)\n",
        "y_theory = np.log2(error_final[0]) - 0.5 * (x_theory - x_theory[0])\n",
        "#plt.plot(x_theory, y_theory, '--', color='blue', linewidth=2,\n",
        "#         alpha=0.8, label=\"Theoretical slope: -1/4\")\n",
        "\n",
        "# Improve axes and labels\n",
        "plt.xlabel(\"$\\\\log_2(N)$\", fontsize=18, fontweight='bold')\n",
        "plt.ylabel(\"$\\\\log_2(\\\\text{Error})$\", fontsize=18, fontweight='bold')\n",
        "plt.title(\"Squared error for the estimation of the W_2 distance, $M = 200$\",\n",
        "          fontsize=20, pad=20)\n",
        "\n",
        "# Add grid for better readability\n",
        "#plt.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
        "#plt.grid(True, alpha=0.2, linestyle=':', linewidth=0.5, which='minor')\n",
        "\n",
        "# Improve tick labels\n",
        "plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "plt.tick_params(axis='both', which='minor', labelsize=10)\n",
        "\n",
        "# Add legend\n",
        "# plt.legend(fontsize=12, loc='best', framealpha=0.9)\n",
        "\n",
        "# Tight layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Optional: Add text box with slope information\n",
        "#slope = np.polyfit(np.log2(N_vec_bis), np.log2(error_final), 1)[0]\n",
        "#plt.text(0.05, 0.95, f'Observed slope: {slope:.3f}',\n",
        "#         transform=plt.gca().transAxes, fontsize=12,\n",
        " #        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.8),\n",
        "  #       verticalalignment='top')\n",
        "\n",
        "# Save as EPS\n",
        "#plt.savefig('/content/drive/MyDrive/Results_OU_M200/OU_M200_bis.eps', format='eps', dpi=300, bbox_inches='tight')\n",
        "#plt.show()\n",
        "#files.download('/content/drive/MyDrive/Results_OU_M200/OU_M200_bis.eps')"
      ],
      "metadata": {
        "id": "hJ68CCTMdXxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sOaywXlZpfw"
      },
      "source": [
        "The least-square estimate of the slope of the above curve is the following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u91BRmomZpfx"
      },
      "outputs": [],
      "source": [
        "X=np.log2(N_vec).reshape(-1,1)\n",
        "y=np.log2(np.sqrt(error_final))\n",
        "reg_Gaussian = LinearRegression().fit(X, y)\n",
        "print (\"The estimate of the slope is\", reg_Gaussian.coef_)\n",
        "print (\"The estimate of the intercept is\", reg_Gaussian.intercept_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg4nUS-ANJHy"
      },
      "source": [
        "# III/ Simulation with $M = N^\\alpha$. <a class=\"anchor\" id=\"chapter3\"></a>\n",
        "\n",
        "## 1) Simulation\n",
        "\n",
        "The code of this section is used to generate [1, Figure 2]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvDjCax2NIUv"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "\n",
        "T=1.\n",
        "m_X0=0  # Mean of the distribution of X_0\n",
        "pn=10\n",
        "base = 9\n",
        "alpha = .26\n",
        "N_power=np.linspace(base,base+pn-1,pn)\n",
        "print (N_power)\n",
        "N_vec=2**N_power.astype(int) # Number of particles, from 2^7 to 2^15\n",
        "M_vec = np.ceil(N_vec**(alpha))\n",
        "print(N_vec)\n",
        "print(M_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwC2gemXN8Wk"
      },
      "outputs": [],
      "source": [
        "## Check the destination path in the function one_sim below before executing this cell\n",
        "\n",
        "NNs = 30\n",
        "\n",
        "start = time.time()\n",
        "for i in range(pn):\n",
        "      M = M_vec[i].astype(int)\n",
        "      h = T/M\n",
        "      print(\"Step \"+str(i)+\", M = \"+str(M)+\", N = \"+str(N_vec[i]))\n",
        "      Parallel(n_jobs = 4)(delayed(one_sim)(N_vec[i], j, M, h) for j in tqdm(range(NNs)))\n",
        "end = time.time()\n",
        "print(end-start)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex3h90RSsOI8"
      },
      "source": [
        "## 2) Estimation of the Wasserstein distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTnCd0m3PWIu"
      },
      "outputs": [],
      "source": [
        "epsilon = 10**(-6) ## can't compute int_0^1 with quantiles as this gives infinite values\n",
        "# epsilon is the truncation value\n",
        "p = 2\n",
        "NNs = 30\n",
        "precision_integral = 10**6\n",
        "quantile_vector = np.arange(0.01,1,1/precision_integral)\n",
        "quantile_theoretical = norm.ppf(quantile_vector, 0, np.sqrt(var_approx))\n",
        "error_basic = np.zeros((pn, NNs))\n",
        "max_error = np.zeros((pn, NNs))\n",
        "error_final = np.zeros(pn)\n",
        "for i in tqdm(range(pn)):   ## particle number\n",
        "    for nns in range(NNs):  ## Monte-Carlo repetition\n",
        "        M = int(M_vec[i])\n",
        "        h = T/M\n",
        "        #print(\"N = \"+str(N_vec[i])+\", M = \"+str(M))\n",
        "        ## Change the second line below to access data stored somewhere else.\n",
        "        path = \"particle_num_\"+str(N_vec[i])+\"repeat\"+str(nns)+\"step\"+str(M)+\".csv\"\n",
        "        density_particle= np.array(pd.read_csv(\"/content/drive/MyDrive/Results_OU_MN26/\"+path, sep=',',header=None))\n",
        "        ## We have NNs simulations with 2^7 particles for instance. Here we upload the last iteration (result at time T).\n",
        "        ## Let us estimate the Wasserstein distance with respect to the true distribution.\n",
        "        quantile_method = np.quantile(density_particle, quantile_vector)\n",
        "        error_basic[i, nns] = estim_Wp(quantile_method, quantile_theoretical, epsilon, p)\n",
        "\n",
        "    ### Computing the finate global error\n",
        "    error_final[i] = np.mean(error_basic[i,:]**p)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Results_OU_MN26/error_final.csv\"\n",
        "np.savetxt(path, error_final, delimiter=\",\")"
      ],
      "metadata": {
        "id": "uGCNLBJob0A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZNjyvWOuKS7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(np.log2(N_vec),np.log2(np.sqrt(error_final)), color = \"blue\", marker = \"o\")\n",
        "\n",
        "plt.xlabel('log2(N)', fontsize=14) # Adjust fontsize as needed\n",
        "plt.ylabel('log2(Error)', fontsize=14) # Adjust fontsize as needed\n",
        "plt.title(r'Squared Error for the estimation of the Wasserstein distance, $M = N^{0.26}$', fontsize=16) # Adjust fontsize as needed\n",
        "plt.grid(False)\n",
        "\n",
        "# Increase tick label size\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.savefig('OUMN26.eps', format='eps', bbox_inches='tight')\n",
        "files.download('OUMN26.eps')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouS41cE56pQT"
      },
      "outputs": [],
      "source": [
        "X=np.log2(N_vec).reshape(-1,1)\n",
        "y=np.log2(np.sqrt(error_final))\n",
        "reg_Gaussian = LinearRegression().fit(X, y)\n",
        "print (\"The estimate of the slope is\", reg_Gaussian.coef_)\n",
        "print (\"The estimate of the intercept is\", reg_Gaussian.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X94oRGKGMmty"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}